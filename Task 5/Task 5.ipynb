{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.3441117  -2.15213913 -2.13772353 -0.80883477 -0.3006734   1.76903389\n",
      "  -0.93918217  0.20546225  0.03430348  0.5233915   1.35142546 -0.3653134\n",
      "  -0.9430384   0.8061167  -0.62695724 -1.11008051 -0.8654561  -0.23018882\n",
      "  -0.12521189  0.54526354  0.36765452 -0.19367761  1.46609845  2.00228453\n",
      "  -0.9257484  -1.65873233  1.56618552  0.38920355  0.05698624 -1.57268581\n",
      "  -0.07668523 -1.49197177 -0.38581534  1.28198264  0.2498175  -0.77124086\n",
      "   0.54783516  0.10758063  1.06292169  0.2052269  -0.49521947 -0.47727688\n",
      "  -0.95705646 -0.80937623 -0.4783884  -0.16668473  0.32603167  0.07070009\n",
      "  -1.4944557  -0.10521428]]\n",
      "\n",
      "[0 1 1 1 1 0 0 1 1 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(n_samples=500, n_features=50, random_state=1)\n",
    "\n",
    "print(str(X[:1]) + \"\\n\\n\" + str(y[:10]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [  1   2   3   7   8  10  15  20  21  22  24  25  26  28  30  32  33  35\n",
      "  36  37  42  43  44  45  48  49  50  52  53  54  55  56  57  60  63  64\n",
      "  68  71  72  74  75  76  77  79  83  84  86  87  94  96  97  99 100 103\n",
      " 104 108 109 113 114 115 116 118 121 126 129 130 133 134 136 137 140 141\n",
      " 143 144 148 149 151 152 153 154 155 156 158 160 166 169 170 175 176 177\n",
      " 178 181 182 183 184 190 193 194 195 196 198 199 200 202 203 205 209 210\n",
      " 211 212 215 216 217 219 220 222 226 227 228 229 231 234 235 237 239 240\n",
      " 241 243 248 251 252 253 254 255 259 262 263 264 265 266 269 271 276 278\n",
      " 279 280 281 282 287 288 296 297 299 301 302 303 307 308 309 313 316 317\n",
      " 318 319 321 327 328 332 333 335 336 337 338 346 348 352 353 354 355 356\n",
      " 357 358 359 362 363 366 367 368 369 371 377 381 382 383 384 387 390 391\n",
      " 393 394 395 396 398 399 402 403 404 405 408 409 410 411 412 413 418 429\n",
      " 431 432 435 437 439 440 443 445 448 452 453 457 459 460 461 464 465 466\n",
      " 468 471 473 474 478 481 483 484 486 487 489 490 493 494 497 498] \n",
      "\n",
      "TEST: [  0   4   5   6   9  11  12  13  14  16  17  18  19  23  27  29  31  34\n",
      "  38  39  40  41  46  47  51  58  59  61  62  65  66  67  69  70  73  78\n",
      "  80  81  82  85  88  89  90  91  92  93  95  98 101 102 105 106 107 110\n",
      " 111 112 117 119 120 122 123 124 125 127 128 131 132 135 138 139 142 145\n",
      " 146 147 150 157 159 161 162 163 164 165 167 168 171 172 173 174 179 180\n",
      " 185 186 187 188 189 191 192 197 201 204 206 207 208 213 214 218 221 223\n",
      " 224 225 230 232 233 236 238 242 244 245 246 247 249 250 256 257 258 260\n",
      " 261 267 268 270 272 273 274 275 277 283 284 285 286 289 290 291 292 293\n",
      " 294 295 298 300 304 305 306 310 311 312 314 315 320 322 323 324 325 326\n",
      " 329 330 331 334 339 340 341 342 343 344 345 347 349 350 351 360 361 364\n",
      " 365 370 372 373 374 375 376 378 379 380 385 386 388 389 392 397 400 401\n",
      " 406 407 414 415 416 417 419 420 421 422 423 424 425 426 427 428 430 433\n",
      " 434 436 438 441 442 444 446 447 449 450 451 454 455 456 458 462 463 467\n",
      " 469 470 472 475 476 477 479 480 482 485 488 491 492 495 496 499]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TRAIN: [  0   4   5   6   9  11  12  13  14  16  17  18  19  23  27  29  31  34\n",
      "  38  39  40  41  46  47  51  58  59  61  62  65  66  67  69  70  73  78\n",
      "  80  81  82  85  88  89  90  91  92  93  95  98 101 102 105 106 107 110\n",
      " 111 112 117 119 120 122 123 124 125 127 128 131 132 135 138 139 142 145\n",
      " 146 147 150 157 159 161 162 163 164 165 167 168 171 172 173 174 179 180\n",
      " 185 186 187 188 189 191 192 197 201 204 206 207 208 213 214 218 221 223\n",
      " 224 225 230 232 233 236 238 242 244 245 246 247 249 250 256 257 258 260\n",
      " 261 267 268 270 272 273 274 275 277 283 284 285 286 289 290 291 292 293\n",
      " 294 295 298 300 304 305 306 310 311 312 314 315 320 322 323 324 325 326\n",
      " 329 330 331 334 339 340 341 342 343 344 345 347 349 350 351 360 361 364\n",
      " 365 370 372 373 374 375 376 378 379 380 385 386 388 389 392 397 400 401\n",
      " 406 407 414 415 416 417 419 420 421 422 423 424 425 426 427 428 430 433\n",
      " 434 436 438 441 442 444 446 447 449 450 451 454 455 456 458 462 463 467\n",
      " 469 470 472 475 476 477 479 480 482 485 488 491 492 495 496 499] \n",
      "\n",
      "TEST: [  1   2   3   7   8  10  15  20  21  22  24  25  26  28  30  32  33  35\n",
      "  36  37  42  43  44  45  48  49  50  52  53  54  55  56  57  60  63  64\n",
      "  68  71  72  74  75  76  77  79  83  84  86  87  94  96  97  99 100 103\n",
      " 104 108 109 113 114 115 116 118 121 126 129 130 133 134 136 137 140 141\n",
      " 143 144 148 149 151 152 153 154 155 156 158 160 166 169 170 175 176 177\n",
      " 178 181 182 183 184 190 193 194 195 196 198 199 200 202 203 205 209 210\n",
      " 211 212 215 216 217 219 220 222 226 227 228 229 231 234 235 237 239 240\n",
      " 241 243 248 251 252 253 254 255 259 262 263 264 265 266 269 271 276 278\n",
      " 279 280 281 282 287 288 296 297 299 301 302 303 307 308 309 313 316 317\n",
      " 318 319 321 327 328 332 333 335 336 337 338 346 348 352 353 354 355 356\n",
      " 357 358 359 362 363 366 367 368 369 371 377 381 382 383 384 387 390 391\n",
      " 393 394 395 396 398 399 402 403 404 405 408 409 410 411 412 413 418 429\n",
      " 431 432 435 437 439 440 443 445 448 452 453 457 459 460 461 464 465 466\n",
      " 468 471 473 474 478 481 483 484 486 487 489 490 493 494 497 498]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=2, shuffle=True, random_state=1)\n",
    "fold = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"\\n\\nTEST:\", test_index)\n",
    "    print(\"\\n\\n\\n\")\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    new = [X_train, X_test, y_train, y_test]\n",
    "    fold.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = fold[0]\n",
    "X_train2, X_test2, y_train2, y_test2 = fold[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First decision's probability: [[0.71318737 0.28681263]]\n",
      "\n",
      "First 30 predicts: [0 0 0 0 1 0 0 1 0 0 1 0 1 1 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 0]\n",
      "\n",
      "General Score: 85.6%\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=1, max_iter=3000).fit(X_train1, y_train1)\n",
    "\n",
    "print(\"First decision's probability: \" + str(clf.predict_proba(X_test1[:1])) + \"\\n\")\n",
    "\n",
    "print(\"First 30 predicts: \" + str(clf.predict(X_test1[:30, :])) + \"\\n\")\n",
    "\n",
    "scoreCLF1 = clf.score(X_test1, y_test1)\n",
    "print(\"General Score: \" + str(scoreCLF1*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First decision's probability: [[0.08051917 0.91948083]]\n",
      "\n",
      "First 30 predicts: [1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 1 1 0]\n",
      "\n",
      "General Score: 86.0%\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=1, max_iter=3000).fit(X_train2, y_train2)\n",
    "\n",
    "print(\"First decision's probability: \" + str(clf.predict_proba(X_test2[:1])) + \"\\n\")\n",
    "\n",
    "print(\"First 30 predicts: \" + str(clf.predict(X_test2[:30, :])) + \"\\n\")\n",
    "\n",
    "scoreCLF2 = clf.score(X_test2, y_test2)\n",
    "print(\"General Score: \" + str(scoreCLF2*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.81590469 -0.41935517  1.53205884  2.28673005  0.81649342 -1.37577948\n",
      "  -0.59207456 -1.38647179  0.24782878 -0.31953349  0.844233   -1.29322156\n",
      "  -0.17810439  0.13141286  1.34584742 -0.14943754  0.74247521 -1.1271659\n",
      "  -0.56422276  1.60969422  0.25697661  1.84970094 -0.05698171 -0.16773887\n",
      "   0.54045046  0.05933367  0.20404361 -0.24533929  1.57537141 -0.98897526\n",
      "   0.64463878 -0.72136507 -0.65285392 -0.69760887  0.7340101  -0.21575808\n",
      "  -0.01481801 -0.15767018 -0.64863754  0.39045766 -0.00524184  0.25822572\n",
      "   0.43381602 -1.67711548  1.07583729 -2.05619206 -0.34662541 -0.60566329\n",
      "   0.23819194 -0.48348679]]\n",
      "\n",
      "[ 298.03194692  113.10350768  534.95319183   61.84238804  -88.00871123\n",
      "  -92.10315116  149.53583815 -234.46533876   67.90235631   35.19329929]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X, y = make_regression(n_samples=500, n_features=50, random_state=1)\n",
    "\n",
    "print(str(X[:1]) + \"\\n\\n\" + str(y[:10]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [  1   2   3   7   8  10  15  20  21  22  24  25  26  28  30  32  33  35\n",
      "  36  37  42  43  44  45  48  49  50  52  53  54  55  56  57  60  63  64\n",
      "  68  71  72  74  75  76  77  79  83  84  86  87  94  96  97  99 100 103\n",
      " 104 108 109 113 114 115 116 118 121 126 129 130 133 134 136 137 140 141\n",
      " 143 144 148 149 151 152 153 154 155 156 158 160 166 169 170 175 176 177\n",
      " 178 181 182 183 184 190 193 194 195 196 198 199 200 202 203 205 209 210\n",
      " 211 212 215 216 217 219 220 222 226 227 228 229 231 234 235 237 239 240\n",
      " 241 243 248 251 252 253 254 255 259 262 263 264 265 266 269 271 276 278\n",
      " 279 280 281 282 287 288 296 297 299 301 302 303 307 308 309 313 316 317\n",
      " 318 319 321 327 328 332 333 335 336 337 338 346 348 352 353 354 355 356\n",
      " 357 358 359 362 363 366 367 368 369 371 377 381 382 383 384 387 390 391\n",
      " 393 394 395 396 398 399 402 403 404 405 408 409 410 411 412 413 418 429\n",
      " 431 432 435 437 439 440 443 445 448 452 453 457 459 460 461 464 465 466\n",
      " 468 471 473 474 478 481 483 484 486 487 489 490 493 494 497 498] \n",
      "\n",
      "TEST: [  0   4   5   6   9  11  12  13  14  16  17  18  19  23  27  29  31  34\n",
      "  38  39  40  41  46  47  51  58  59  61  62  65  66  67  69  70  73  78\n",
      "  80  81  82  85  88  89  90  91  92  93  95  98 101 102 105 106 107 110\n",
      " 111 112 117 119 120 122 123 124 125 127 128 131 132 135 138 139 142 145\n",
      " 146 147 150 157 159 161 162 163 164 165 167 168 171 172 173 174 179 180\n",
      " 185 186 187 188 189 191 192 197 201 204 206 207 208 213 214 218 221 223\n",
      " 224 225 230 232 233 236 238 242 244 245 246 247 249 250 256 257 258 260\n",
      " 261 267 268 270 272 273 274 275 277 283 284 285 286 289 290 291 292 293\n",
      " 294 295 298 300 304 305 306 310 311 312 314 315 320 322 323 324 325 326\n",
      " 329 330 331 334 339 340 341 342 343 344 345 347 349 350 351 360 361 364\n",
      " 365 370 372 373 374 375 376 378 379 380 385 386 388 389 392 397 400 401\n",
      " 406 407 414 415 416 417 419 420 421 422 423 424 425 426 427 428 430 433\n",
      " 434 436 438 441 442 444 446 447 449 450 451 454 455 456 458 462 463 467\n",
      " 469 470 472 475 476 477 479 480 482 485 488 491 492 495 496 499]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TRAIN: [  0   4   5   6   9  11  12  13  14  16  17  18  19  23  27  29  31  34\n",
      "  38  39  40  41  46  47  51  58  59  61  62  65  66  67  69  70  73  78\n",
      "  80  81  82  85  88  89  90  91  92  93  95  98 101 102 105 106 107 110\n",
      " 111 112 117 119 120 122 123 124 125 127 128 131 132 135 138 139 142 145\n",
      " 146 147 150 157 159 161 162 163 164 165 167 168 171 172 173 174 179 180\n",
      " 185 186 187 188 189 191 192 197 201 204 206 207 208 213 214 218 221 223\n",
      " 224 225 230 232 233 236 238 242 244 245 246 247 249 250 256 257 258 260\n",
      " 261 267 268 270 272 273 274 275 277 283 284 285 286 289 290 291 292 293\n",
      " 294 295 298 300 304 305 306 310 311 312 314 315 320 322 323 324 325 326\n",
      " 329 330 331 334 339 340 341 342 343 344 345 347 349 350 351 360 361 364\n",
      " 365 370 372 373 374 375 376 378 379 380 385 386 388 389 392 397 400 401\n",
      " 406 407 414 415 416 417 419 420 421 422 423 424 425 426 427 428 430 433\n",
      " 434 436 438 441 442 444 446 447 449 450 451 454 455 456 458 462 463 467\n",
      " 469 470 472 475 476 477 479 480 482 485 488 491 492 495 496 499] \n",
      "\n",
      "TEST: [  1   2   3   7   8  10  15  20  21  22  24  25  26  28  30  32  33  35\n",
      "  36  37  42  43  44  45  48  49  50  52  53  54  55  56  57  60  63  64\n",
      "  68  71  72  74  75  76  77  79  83  84  86  87  94  96  97  99 100 103\n",
      " 104 108 109 113 114 115 116 118 121 126 129 130 133 134 136 137 140 141\n",
      " 143 144 148 149 151 152 153 154 155 156 158 160 166 169 170 175 176 177\n",
      " 178 181 182 183 184 190 193 194 195 196 198 199 200 202 203 205 209 210\n",
      " 211 212 215 216 217 219 220 222 226 227 228 229 231 234 235 237 239 240\n",
      " 241 243 248 251 252 253 254 255 259 262 263 264 265 266 269 271 276 278\n",
      " 279 280 281 282 287 288 296 297 299 301 302 303 307 308 309 313 316 317\n",
      " 318 319 321 327 328 332 333 335 336 337 338 346 348 352 353 354 355 356\n",
      " 357 358 359 362 363 366 367 368 369 371 377 381 382 383 384 387 390 391\n",
      " 393 394 395 396 398 399 402 403 404 405 408 409 410 411 412 413 418 429\n",
      " 431 432 435 437 439 440 443 445 448 452 453 457 459 460 461 464 465 466\n",
      " 468 471 473 474 478 481 483 484 486 487 489 490 493 494 497 498]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=2, shuffle=True, random_state=1)\n",
    "fold = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"\\n\\nTEST:\", test_index)\n",
    "    print(\"\\n\\n\\n\")\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    new = [X_train, X_test, y_train, y_test]\n",
    "    fold.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = fold[0]\n",
    "X_train2, X_test2, y_train2, y_test2 = fold[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 30 predicts: [ 265.60747815  -48.28496478  -73.16845285  150.34924993   29.4136977\n",
      "   72.26733779   34.64638601   73.19127281  -43.41601198  -24.57875501\n",
      " -114.12743521  202.86370117 -206.92905848  -97.04053087 -107.5851548\n",
      "  320.7175927    47.39796975 -261.42844086   80.75774316  204.14021466\n",
      " -160.78097581 -143.32863387  142.04103303 -139.23909229  -31.07027181\n",
      "  -17.62147568   56.79639792  -23.94282687  109.80020034  115.19196933]\n",
      "\n",
      "General Score: 96.82896239339881%\n"
     ]
    }
   ],
   "source": [
    "regr = MLPRegressor(random_state=1, max_iter=3000).fit(X_train1, y_train1)\n",
    "\n",
    "print(\"First 30 predicts: \" + str(regr.predict(X_test1[:30, :])) + \"\\n\")\n",
    "\n",
    "scoreRegr1 = regr.score(X_test1, y_test1)\n",
    "print(\"General Score: \" + str(scoreRegr1*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 30 predicts: [  76.10905665  506.17307321   36.48355525 -181.34466666   71.40170114\n",
      " -290.59825194 -149.5051373   -28.27032972 -184.70417789  121.70069051\n",
      "  119.49368309 -314.95357869 -214.91855773  -55.35056982  -18.99955653\n",
      " -210.3351233  -172.58241663  -91.25462774 -132.18339279  122.62695662\n",
      " -184.71892294  153.50788793  199.26418943  270.91085598 -212.83979795\n",
      "   10.07908416  -99.00498703   71.80647095  -99.03506165   10.41943556]\n",
      "\n",
      "General Score: 96.13352447347829%\n"
     ]
    }
   ],
   "source": [
    "regr = MLPRegressor(random_state=1, max_iter=3000).fit(X_train2, y_train2)\n",
    "\n",
    "print(\"First 30 predicts: \" + str(regr.predict(X_test2[:30, :])) + \"\\n\")\n",
    "\n",
    "scoreRegr2 = regr.score(X_test2, y_test2)\n",
    "print(\"General Score: \" + str(scoreRegr2*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreClf = (scoreCLF1 + scoreCLF2) / 2\n",
    "scoreRegr = (scoreRegr1 + scoreRegr2) / 2\n",
    "\n",
    "print(\"Score for MLP Classifier: \" + str(round(scoreClf,3)) + \"\\n\" + \"Score for MLP Regressor: \" + str(round(scoreRegr,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
